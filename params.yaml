dnn_params:
  batch_size: 32
  learning_rate: 0.001
  epochs: 100
  dropout_rates:
    layer_1: 0.2
    layer_2: 0.25
    layer_3: 0.2
  optimizer: Adam
  loss_function: BCELoss
  activation_function: relu

  